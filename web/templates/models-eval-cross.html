<!--
  Copyright 2018 Google LLC

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE html>
<html lang="en" xml:lang="en" xmlns= "http://www.w3.org/1999/xhtml">
  {% from "macros.html" import models_link,
      bootstrap_links, favicon_links, navbar, tip with context %}
  {% macro eval_link(model, display) %}
    <a href="{{ url_for('model_eval',
                        bucket=bucket,
                        model_name=model,
                        sorted=is_sorted) }}">{{ display }}</a>
  {% endmacro %}
  <head lang="en">
      <meta charset="UTF-8">
      <meta http-equiv="Content-Language" content="en">
      <meta name="google" content="notranslate">
      <title>Minigo Model Eval</title>

      {{ favicon_links() }}
      {{ bootstrap_links() }}

      <link rel="stylesheet" type="text/css" href="{{ url_for('static',filename='styles/general.css') }}">
      <link rel="stylesheet" type="text/css" href="{{ url_for('static',filename='styles/table.css') }}">

      <script src="https://d3js.org/d3.v4.min.js"></script>
      <script type="text/javascript" src="{{ url_for('static',filename='d3-tip.js') }}"></script>
      <script type="text/javascript" src="{{ url_for('static',filename='graphs.js') }}"></script>

      <style>
        .model-graph {
          margin: 20px;
          width: 600px;
          height: 600px;
        }
        .filter-good-models,
        .filter-recent-models,
        .model-graph,
        .rating-desc,
        .rating-graphs,
        .winrate-scatter {
          display: inline-block;
        }
        .rating-desc {
          vertical-align: top;
          margin-top: 50px;
          margin-right: 20px;
        }
        .filter-good-models,
        .filter-recent-models {
          margin-top: 10px;
        }

        .great-model {
          font-weight: bold;
          color: #151;
        }

        .scatter-text {
          color: white;
          font-weight: bold;
          background: #000;
          padding: 4px;
          border-radius: 4px;
        }

        .error-line {
          stroke-dasharray: 2, 6;
        }

        /* Creates a small triangle extender for the tooltip */
        .d3-tip.s:after {
          position: absolute;
          width: 100%;
          text-align: center;
          left: 0;
          top: -14px;
          color: #000;
          content: "\25B2";
        }

      </style>
  </head>
  <body>
    {{ navbar('eval_graphs', 'Evaluation ratings') }}

    {% set num_models = sorted_models|length %}
    <div>
      <h6>
        This page is generated by joining eval games from a number of runs with
        {{cross_run_games}} extra games played between models of different
        runs and calculating ratings over all those games.<br><br>
{% if bucket == 'cross-run-eval' %}
        100 models were choosen from each recent run, 75 good models chosen
        evenly along the run and 25 of the strongest models.<br>
        Any games played between these models were kept and additional games
        have been played between models not in the same run, to provide a
        more accurate rating.<br><br>
{% endif %}
        These ratings are less inflated than self-play elo because models face
        a wider more diverse set of opponents.
      </h6>
    </div>
    <hr>

    <div class="ratings-graphs">
      <svg class="model-graph" id="rating-svg"></svg>
      <div class="rating-desc">
        <table class="table table-striped table-hover">
          <tbody>
          <tr>
            <td>Ratings from</td>
            <td>{{ total_games }} games shown</td>
            <td>rating</td>
            <td>uncertainty</td>
          </tr>

          {% for model in sorted_models[:15] + sorted_models[-1:] %}
          <tr class={{"great-model" if not loop.last else ""}}>
            <td>{{ "Best model" if loop.first else
                  ("Worst model" if loop.last else loop.index) }}</td>
            <td>{{ eval_link(model[2], model[0] + "/" + model[3]) }}</td>
            <td>{{model[4]|round|int }}</td>
            <td>&plusmn; {{ model[5]|round|int }}</td>
          </tr>
          {% endfor %}
          <tr>
            <td>Averages</td>
            <td>-</td>
            <td>{{ (sorted_models|sum(attribute="4") / num_models)|round|int }}</td>
            <td>&plusmn; {{ (sorted_models|sum(attribute="5") / num_models)|round(2) }}</td>
          </tr>
          </tbody>
        </table>
        <label class="filter-good-models">
            <input id="filter-good-models" type="checkbox">
            Filter bad models
        </label>
        <label class="filter-recent-models">
            <input id="filter-recent-models" type="checkbox">
            Filter old models
        </label>
      </div>
      <div class="rating-desc">
        <table class="table table-striped table-hover">
          <tbody>
          <tr>
            <td>Games</td>
            <td>Models with many games</td>
            <td>rating</td>
          </tr>

          {% for model in well_played_models[:17] %}
          <tr class="great-model">
            <td>{{ model[6] }}</td>
            <td>{{ eval_link(model[2], model[0] + "/" + model[3]) }}</td>
            <td>{{model[4]|round|int }}</td>
          </tr>
          {% endfor %}
          </tbody>
        </table>
      </div>
    </div>
    <hr>
    {% set model_list = sorted_models %}
    {% set rows = 50 %}
    {% set columns = (num_models - 1 + rows) // rows %}
    {% for c in range(columns) %}
    <table class="table table-striped table-hover models-table">
      <thead class="thead-light">
        <th>Model</th>
        <th class="c-tooltip">
          Rating
          {{ tip("We use python choix to calculate bradley-terry model ratings then multiplying by 400 / ln(10) to approximate elo") }}
        </th>
        <th>Games</th>
      </thead>
      <tbody>
      {% for data in model_list[c*rows:(c+1)*rows] %}
      <tr class="eval-model">
        <td>{{ eval_link(data[2], data[0] + "/" + data[3]) }}</a></td>
        <td>{{ data[4]|round|int }}
            {%- if data[5] > 80 %} (&plusmn;{{ data[5]|round|int }}){% endif -%}
        </td>
        <td>{{ data[6] }}</td>
      </tr>
      {% endfor %}
      </tbody>
    </table>
    {% endfor %}
  </body>

  <script type="text/javascript">
    {# Have to reverse models so that filter works #}
    var ratings = JSON.parse('{{ models[::-1] | tojson | safe }}');
    var model_goodness_filter = d3.select("#filter-good-models")
    var model_recency_filter = d3.select("#filter-recent-models")
    var rating_svg = d3.select("#rating-svg");

    function plot_ratings() {
      var goodness_checked = model_goodness_filter.node().checked;
      var recency_checked = model_recency_filter.node().checked;

      var model_fn = function(d) { return d[1]; };

      var max_model = d3.max(ratings, model_fn);

      var new_ratings = ratings.filter(function(r, i) {
        sawBetter = false;
        for (j = Math.max(0, i - 3); j < i; j++) {
          if (ratings[j][4] > r[4]) {
            sawBetter = true;
          }
        }

        var result = true;
        if (goodness_checked) {
          result &= !sawBetter;
        }
        if (recency_checked) {
          result &= model_fn(r) * 100 > max_model * 40;
        }
        return result;
      });

      rating_svg.selectAll("*").remove();
      d3.selectAll(".d3-tip.scatter-text").remove();

      rating_scatter_plot(
          rating_svg,
          new_ratings,
          function(d) { return d[4]; },
          function(d) { return d[5]; },
          function(d) { return d[0]; },
          model_fn,
          "Rating",
          "Model",
          "Rating (elo like)");
    }

    model_goodness_filter.on("change", plot_ratings);
    model_recency_filter.on("change", plot_ratings);

    plot_ratings();
  </script>
</html>
